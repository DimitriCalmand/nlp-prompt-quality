{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T14:04:39.296701Z",
     "start_time": "2025-05-12T14:04:38.031302Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# On charge directement le split train/validation/test\n",
    "dataset = load_dataset(\"ibm-research/argument_quality_ranking_30k\", \"argument_quality_ranking\")\n",
    "\n",
    "# Aperçu rapide\n",
    "print(dataset)\n",
    "dataset[\"train\"][0]"
   ],
   "id": "990a3db89840c9ed",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['argument', 'topic', 'set', 'WA', 'MACE-P', 'stance_WA', 'stance_WA_conf'],\n",
      "        num_rows: 20974\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['argument', 'topic', 'set', 'WA', 'MACE-P', 'stance_WA', 'stance_WA_conf'],\n",
      "        num_rows: 3208\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['argument', 'topic', 'set', 'WA', 'MACE-P', 'stance_WA', 'stance_WA_conf'],\n",
      "        num_rows: 6315\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'argument': '\"marriage\" isn\\'t keeping up with the times.  abandon the old thinking and bring something that incorporates all unions - not just those with a man and woman.',\n",
       " 'topic': 'We should abandon marriage',\n",
       " 'set': 'train',\n",
       " 'WA': 0.846164614,\n",
       " 'MACE-P': 0.297659077,\n",
       " 'stance_WA': 1,\n",
       " 'stance_WA_conf': 1.0}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 134
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T14:04:39.456905Z",
     "start_time": "2025-05-12T14:04:39.301105Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import BertTokenizerFast\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Fonction de tokenisation\n",
    "def preprocess(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"argument\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=128\n",
    "    )\n",
    "\n",
    "# Appliquez la tokenisation sans retirer toutes les colonnes\n",
    "tokenized = dataset.map(\n",
    "    preprocess,\n",
    "    batched=True,\n",
    "    # ne retirez QUE les colonnes texte brutes inutiles,\n",
    "    # mais conservez MACE-P\n",
    "    remove_columns=[\"argument\", \"topic\", \"set\", \"WA\", \"stance_WA\", \"stance_WA_conf\"]\n",
    ")"
   ],
   "id": "eb4672e3ec9b2718",
   "outputs": [],
   "execution_count": 135
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T14:04:40.422966Z",
     "start_time": "2025-05-12T14:04:39.468324Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def to_tf_dataset(split):\n",
    "    # Features: input_ids, attention_mask → X ; label: MACE-P → y\n",
    "    features = {\n",
    "        \"input_ids\": tf.constant(split[\"input_ids\"], dtype=tf.int32),\n",
    "        \"attention_mask\": tf.constant(split[\"attention_mask\"], dtype=tf.int32),\n",
    "    }\n",
    "    labels = tf.constant(split[\"MACE-P\"], dtype=tf.float32)\n",
    "    return tf.data.Dataset.from_tensor_slices((features, labels))\n",
    "\n",
    "train_ds = to_tf_dataset(tokenized[\"train\"]).shuffle(10_000).batch(32)\n",
    "val_ds   = to_tf_dataset(tokenized[\"validation\"]).batch(32)\n",
    "test_ds  = to_tf_dataset(tokenized[\"test\"]).batch(32)"
   ],
   "id": "6dda7b9cfff67841",
   "outputs": [],
   "execution_count": 136
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T14:04:40.436465Z",
     "start_time": "2025-05-12T14:04:40.432329Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers.schedules import LearningRateSchedule, CosineDecayRestarts\n",
    "\n",
    "# 1. CosineDecayRestarts pour snapshots et redémarrages\n",
    "decay_schedule = CosineDecayRestarts(\n",
    "    initial_learning_rate=3e-5,\n",
    "    first_decay_steps=1000,   # ajuster selon nb_steps\n",
    "    t_mul=2.0,\n",
    "    m_mul=1.0,\n",
    "    alpha=0.0\n",
    ")\n",
    "\n",
    "# 2. Classe WarmUp pour une montée linéaire des LR\n",
    "class WarmUp(LearningRateSchedule):\n",
    "    def __init__(self, initial_lr, decay_schedule_fn, warmup_steps):\n",
    "        super().__init__()\n",
    "        # Conservez les valeurs pour la configuration\n",
    "        self.initial_lr = float(initial_lr)\n",
    "        self.warmup_steps = int(warmup_steps)\n",
    "        self.decay_fn = decay_schedule_fn\n",
    "\n",
    "    def __call__(self, step):\n",
    "        step_float = tf.cast(step, tf.float32)\n",
    "        warmup_lr = tf.cast(self.initial_lr, tf.float32) * (step_float / tf.cast(self.warmup_steps, tf.float32))\n",
    "        decay_lr = self.decay_fn(step - self.warmup_steps)\n",
    "        return tf.where(step_float < self.warmup_steps, warmup_lr, decay_lr)\n",
    "\n",
    "    def get_config(self):\n",
    "        # Nécessaire pour la sérialisation du scheduler\n",
    "        return {\n",
    "            \"initial_lr\": self.initial_lr,\n",
    "            \"warmup_steps\": self.warmup_steps,\n",
    "            \"decay_schedule_fn\": tf.keras.optimizers.schedules.deserialize(\n",
    "                {\n",
    "                    \"class_name\": self.decay_fn.__class__.__name__,\n",
    "                    \"config\": self.decay_fn.get_config()\n",
    "                }\n",
    "            )\n",
    "        }\n",
    "\n",
    "lr_schedule = WarmUp(\n",
    "    initial_lr=3e-5,\n",
    "    decay_schedule_fn=decay_schedule,\n",
    "    warmup_steps=500\n",
    ")\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)"
   ],
   "id": "2bf1e9081994ad2f",
   "outputs": [],
   "execution_count": 137
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T14:04:40.795165Z",
     "start_time": "2025-05-12T14:04:40.719484Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "class PositionalEncoding(layers.Layer):\n",
    "    def __init__(self, max_len, d_model):\n",
    "        super().__init__()\n",
    "        pos = tf.range(max_len, dtype=tf.float32)[:, tf.newaxis]\n",
    "        i   = tf.range(d_model, dtype=tf.float32)[tf.newaxis, :]\n",
    "        angle = pos / tf.pow(10000.0, (2 * (i//2)) / tf.cast(d_model, tf.float32))\n",
    "        pe = tf.where(tf.cast(i, tf.int32) % 2 == 0, tf.sin(angle), tf.cos(angle))\n",
    "        self.pe = pe[tf.newaxis, ...]\n",
    "\n",
    "    def call(self, x):\n",
    "        return x + self.pe[:, :tf.shape(x)[1], :]\n",
    "\n",
    "def build_transformer_model(\n",
    "    vocab_size: int,\n",
    "    max_len: int = 128,\n",
    "    d_model: int = 128,\n",
    "    num_heads: int = 4,\n",
    "    ff_dim: int = 256,\n",
    "    num_layers: int = 2,\n",
    "):\n",
    "    input_ids = layers.Input(shape=(max_len,), dtype=tf.int32, name=\"input_ids\")\n",
    "    att_mask  = layers.Input(shape=(max_len,), dtype=tf.int32, name=\"attention_mask\")\n",
    "\n",
    "    x = layers.Embedding(vocab_size, d_model)(input_ids)\n",
    "    x = layers.Dropout(0.1)(x)                       # dropout sur embeddings\n",
    "\n",
    "    x = PositionalEncoding(max_len, d_model)(x)\n",
    "\n",
    "    for _ in range(num_layers):\n",
    "        # Multi-head Self-Attention\n",
    "        attn_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads,\n",
    "            key_dim=d_model,\n",
    "            dropout=0.1\n",
    "        )(x, x, attention_mask=att_mask[:, tf.newaxis, tf.newaxis, :])\n",
    "        attn_output = layers.Dropout(0.1)(attn_output)  # dropout sur attention\n",
    "        attn_output = layers.LayerNormalization(epsilon=1e-6)(x + attn_output)\n",
    "\n",
    "        # Feed-forward\n",
    "        ff = layers.Dense(ff_dim, activation=\"relu\")(attn_output)\n",
    "        ff = layers.Dropout(0.1)(ff)                   # dropout feed-forward\n",
    "        ff = layers.Dense(d_model)(ff)\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(attn_output + ff)\n",
    "\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    output = layers.Dense(1, activation=\"linear\", name=\"mace_p\")(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=[input_ids, att_mask], outputs=output)\n",
    "\n",
    "vocab_size = tokenizer.vocab_size  # supposant que tokenizer est déjà chargé\n",
    "model = build_transformer_model(vocab_size)\n",
    "model.summary()"
   ],
   "id": "a9f34d71344cda3f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"functional_4\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_4\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)       \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape     \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m   Param #\u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mConnected to     \u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_ids           │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m)       │          \u001B[38;5;34m0\u001B[0m │ -                 │\n",
       "│ (\u001B[38;5;33mInputLayer\u001B[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_4         │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m, \u001B[38;5;34m128\u001B[0m)  │  \u001B[38;5;34m3,906,816\u001B[0m │ input_ids[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]   │\n",
       "│ (\u001B[38;5;33mEmbedding\u001B[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_23          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m, \u001B[38;5;34m128\u001B[0m)  │          \u001B[38;5;34m0\u001B[0m │ embedding_4[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m] │\n",
       "│ (\u001B[38;5;33mDropout\u001B[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ attention_mask      │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m)       │          \u001B[38;5;34m0\u001B[0m │ -                 │\n",
       "│ (\u001B[38;5;33mInputLayer\u001B[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ positional_encodin… │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m, \u001B[38;5;34m128\u001B[0m)  │          \u001B[38;5;34m0\u001B[0m │ dropout_23[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]  │\n",
       "│ (\u001B[38;5;33mPositionalEncodin…\u001B[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ get_item_8          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m, \u001B[38;5;34m1\u001B[0m, \u001B[38;5;34m128\u001B[0m) │          \u001B[38;5;34m0\u001B[0m │ attention_mask[\u001B[38;5;34m0\u001B[0m… │\n",
       "│ (\u001B[38;5;33mGetItem\u001B[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m, \u001B[38;5;34m128\u001B[0m)  │    \u001B[38;5;34m263,808\u001B[0m │ positional_encod… │\n",
       "│ (\u001B[38;5;33mMultiHeadAttentio…\u001B[0m │                   │            │ positional_encod… │\n",
       "│                     │                   │            │ get_item_8[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_25          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m, \u001B[38;5;34m128\u001B[0m)  │          \u001B[38;5;34m0\u001B[0m │ multi_head_atten… │\n",
       "│ (\u001B[38;5;33mDropout\u001B[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_16 (\u001B[38;5;33mAdd\u001B[0m)        │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m, \u001B[38;5;34m128\u001B[0m)  │          \u001B[38;5;34m0\u001B[0m │ positional_encod… │\n",
       "│                     │                   │            │ dropout_25[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m, \u001B[38;5;34m128\u001B[0m)  │        \u001B[38;5;34m256\u001B[0m │ add_16[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]      │\n",
       "│ (\u001B[38;5;33mLayerNormalizatio…\u001B[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_16 (\u001B[38;5;33mDense\u001B[0m)    │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m, \u001B[38;5;34m256\u001B[0m)  │     \u001B[38;5;34m33,024\u001B[0m │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_26          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m, \u001B[38;5;34m256\u001B[0m)  │          \u001B[38;5;34m0\u001B[0m │ dense_16[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]    │\n",
       "│ (\u001B[38;5;33mDropout\u001B[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_17 (\u001B[38;5;33mDense\u001B[0m)    │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m, \u001B[38;5;34m128\u001B[0m)  │     \u001B[38;5;34m32,896\u001B[0m │ dropout_26[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_17 (\u001B[38;5;33mAdd\u001B[0m)        │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m, \u001B[38;5;34m128\u001B[0m)  │          \u001B[38;5;34m0\u001B[0m │ layer_normalizat… │\n",
       "│                     │                   │            │ dense_17[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m, \u001B[38;5;34m128\u001B[0m)  │        \u001B[38;5;34m256\u001B[0m │ add_17[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]      │\n",
       "│ (\u001B[38;5;33mLayerNormalizatio…\u001B[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ get_item_9          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m, \u001B[38;5;34m1\u001B[0m, \u001B[38;5;34m128\u001B[0m) │          \u001B[38;5;34m0\u001B[0m │ attention_mask[\u001B[38;5;34m0\u001B[0m… │\n",
       "│ (\u001B[38;5;33mGetItem\u001B[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m, \u001B[38;5;34m128\u001B[0m)  │    \u001B[38;5;34m263,808\u001B[0m │ layer_normalizat… │\n",
       "│ (\u001B[38;5;33mMultiHeadAttentio…\u001B[0m │                   │            │ layer_normalizat… │\n",
       "│                     │                   │            │ get_item_9[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_28          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m, \u001B[38;5;34m128\u001B[0m)  │          \u001B[38;5;34m0\u001B[0m │ multi_head_atten… │\n",
       "│ (\u001B[38;5;33mDropout\u001B[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_18 (\u001B[38;5;33mAdd\u001B[0m)        │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m, \u001B[38;5;34m128\u001B[0m)  │          \u001B[38;5;34m0\u001B[0m │ layer_normalizat… │\n",
       "│                     │                   │            │ dropout_28[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m, \u001B[38;5;34m128\u001B[0m)  │        \u001B[38;5;34m256\u001B[0m │ add_18[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]      │\n",
       "│ (\u001B[38;5;33mLayerNormalizatio…\u001B[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_18 (\u001B[38;5;33mDense\u001B[0m)    │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m, \u001B[38;5;34m256\u001B[0m)  │     \u001B[38;5;34m33,024\u001B[0m │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_29          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m, \u001B[38;5;34m256\u001B[0m)  │          \u001B[38;5;34m0\u001B[0m │ dense_18[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]    │\n",
       "│ (\u001B[38;5;33mDropout\u001B[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_19 (\u001B[38;5;33mDense\u001B[0m)    │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m, \u001B[38;5;34m128\u001B[0m)  │     \u001B[38;5;34m32,896\u001B[0m │ dropout_29[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_19 (\u001B[38;5;33mAdd\u001B[0m)        │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m, \u001B[38;5;34m128\u001B[0m)  │          \u001B[38;5;34m0\u001B[0m │ layer_normalizat… │\n",
       "│                     │                   │            │ dense_19[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m, \u001B[38;5;34m128\u001B[0m)  │        \u001B[38;5;34m256\u001B[0m │ add_19[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]      │\n",
       "│ (\u001B[38;5;33mLayerNormalizatio…\u001B[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m)       │          \u001B[38;5;34m0\u001B[0m │ layer_normalizat… │\n",
       "│ (\u001B[38;5;33mGlobalAveragePool…\u001B[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mace_p (\u001B[38;5;33mDense\u001B[0m)      │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)         │        \u001B[38;5;34m129\u001B[0m │ global_average_p… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_ids           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_4         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,906,816</span> │ input_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_23          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ attention_mask      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ positional_encodin… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEncodin…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ get_item_8          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ attention_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,808</span> │ positional_encod… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ positional_encod… │\n",
       "│                     │                   │            │ get_item_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_25          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ positional_encod… │\n",
       "│                     │                   │            │ dropout_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ add_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_26          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dropout_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
       "│                     │                   │            │ dense_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ add_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ get_item_9          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ attention_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,808</span> │ layer_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n",
       "│                     │                   │            │ get_item_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_28          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
       "│                     │                   │            │ dropout_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ add_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_29          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dropout_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
       "│                     │                   │            │ dense_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ add_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mace_p (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ global_average_p… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m4,567,425\u001B[0m (17.42 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,567,425</span> (17.42 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m4,567,425\u001B[0m (17.42 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,567,425</span> (17.42 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 138
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T14:04:42.392877Z",
     "start_time": "2025-05-12T14:04:42.388459Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "class UnfreezeCallback(Callback):\n",
    "    def __init__(self, freeze_epochs=2):\n",
    "        super().__init__()\n",
    "        self.freeze_epochs = freeze_epochs\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        # geler embeddings et première couche d'attention\n",
    "        for layer in self.model.layers:\n",
    "            if isinstance(layer, tf.keras.layers.Embedding) or 'multi_head_attention' in layer.name:\n",
    "                layer.trainable = False\n",
    "        print(\"Couches initiales gelées\")\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch + 1 == self.freeze_epochs:\n",
    "            for layer in self.model.layers:\n",
    "                layer.trainable = True\n",
    "            print(f\"Couches dé-gelées à l'époque {epoch+1}\")\n",
    "\n",
    "unfreeze_cb = UnfreezeCallback(freeze_epochs=2)"
   ],
   "id": "cbd3e19fa500a75d",
   "outputs": [],
   "execution_count": 139
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T14:04:43.791648Z",
     "start_time": "2025-05-12T14:04:43.785068Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,                            # scheduler + Adam\n",
    "    loss=\"mean_squared_error\",\n",
    "    metrics=[tf.keras.metrics.MeanAbsoluteError(name=\"MAE\")]\n",
    ")\n",
    "\n",
    "checkpoint_cb = ModelCheckpoint(\n",
    "    \"best_model.h5\",\n",
    "    monitor=\"val_MAE\",\n",
    "    mode=\"min\",\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "earlystop_cb = EarlyStopping(\n",
    "    monitor=\"val_MAE\",\n",
    "    patience=3,\n",
    "    mode=\"min\",\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "callbacks = [checkpoint_cb, earlystop_cb, unfreeze_cb]"
   ],
   "id": "22a184c265d1a600",
   "outputs": [],
   "execution_count": 140
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T14:15:59.587830Z",
     "start_time": "2025-05-12T14:04:47.745992Z"
    }
   },
   "cell_type": "code",
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=15,\n",
    "    callbacks=callbacks\n",
    ")"
   ],
   "id": "1f6c222db3853a4e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couches initiales gelées\n",
      "Epoch 1/15\n",
      "\u001B[1m656/656\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 111ms/step - MAE: 0.3383 - loss: 0.1542\n",
      "Epoch 1: val_MAE improved from inf to 0.32031, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m656/656\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m81s\u001B[0m 121ms/step - MAE: 0.3383 - loss: 0.1541 - val_MAE: 0.3203 - val_loss: 0.1290\n",
      "Epoch 2/15\n",
      "\u001B[1m656/656\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 106ms/step - MAE: 0.3245 - loss: 0.1328\n",
      "Epoch 2: val_MAE did not improve from 0.32031\n",
      "Couches dé-gelées à l'époque 2\n",
      "\u001B[1m656/656\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m75s\u001B[0m 115ms/step - MAE: 0.3245 - loss: 0.1328 - val_MAE: 0.3225 - val_loss: 0.1287\n",
      "Epoch 3/15\n",
      "\u001B[1m656/656\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 109ms/step - MAE: 0.3223 - loss: 0.1313\n",
      "Epoch 3: val_MAE improved from 0.32031 to 0.31891, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m656/656\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m78s\u001B[0m 118ms/step - MAE: 0.3223 - loss: 0.1313 - val_MAE: 0.3189 - val_loss: 0.1278\n",
      "Epoch 4/15\n",
      "\u001B[1m656/656\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 103ms/step - MAE: 0.3229 - loss: 0.1326\n",
      "Epoch 4: val_MAE improved from 0.31891 to 0.31717, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m656/656\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m73s\u001B[0m 112ms/step - MAE: 0.3229 - loss: 0.1326 - val_MAE: 0.3172 - val_loss: 0.1277\n",
      "Epoch 5/15\n",
      "\u001B[1m655/656\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 105ms/step - MAE: 0.3209 - loss: 0.1308\n",
      "Epoch 5: val_MAE did not improve from 0.31717\n",
      "\u001B[1m656/656\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m75s\u001B[0m 114ms/step - MAE: 0.3210 - loss: 0.1308 - val_MAE: 0.3188 - val_loss: 0.1278\n",
      "Epoch 6/15\n",
      "\u001B[1m656/656\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 98ms/step - MAE: 0.3224 - loss: 0.1315\n",
      "Epoch 6: val_MAE improved from 0.31717 to 0.31262, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m656/656\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m70s\u001B[0m 107ms/step - MAE: 0.3224 - loss: 0.1315 - val_MAE: 0.3126 - val_loss: 0.1293\n",
      "Epoch 7/15\n",
      "\u001B[1m656/656\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 99ms/step - MAE: 0.3223 - loss: 0.1329\n",
      "Epoch 7: val_MAE did not improve from 0.31262\n",
      "\u001B[1m656/656\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m71s\u001B[0m 108ms/step - MAE: 0.3223 - loss: 0.1329 - val_MAE: 0.3243 - val_loss: 0.1297\n",
      "Epoch 8/15\n",
      "\u001B[1m655/656\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 104ms/step - MAE: 0.3227 - loss: 0.1324\n",
      "Epoch 8: val_MAE did not improve from 0.31262\n",
      "\u001B[1m656/656\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m74s\u001B[0m 113ms/step - MAE: 0.3227 - loss: 0.1324 - val_MAE: 0.3143 - val_loss: 0.1282\n",
      "Epoch 9/15\n",
      "\u001B[1m656/656\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 106ms/step - MAE: 0.3205 - loss: 0.1308\n",
      "Epoch 9: val_MAE did not improve from 0.31262\n",
      "\u001B[1m656/656\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m75s\u001B[0m 115ms/step - MAE: 0.3205 - loss: 0.1308 - val_MAE: 0.3240 - val_loss: 0.1294\n",
      "Epoch 9: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n"
     ]
    }
   ],
   "execution_count": 141
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T14:16:21.028518Z",
     "start_time": "2025-05-12T14:16:09.781919Z"
    }
   },
   "cell_type": "code",
   "source": [
    "result = model.evaluate(test_ds)\n",
    "print(f\"Test MAE: {result[1]:.4f}\")"
   ],
   "id": "ce8f6e822798eed7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m198/198\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 57ms/step - MAE: 0.3211 - loss: 0.1377\n",
      "Test MAE: 0.3200\n"
     ]
    }
   ],
   "execution_count": 142
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ca3184f373dae4e0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
