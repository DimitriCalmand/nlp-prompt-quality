{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dimitri/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Suppress INFO and WARNING messages\n",
    "import argparse\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import joblib\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "## train test split\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "n_missing = 3\n",
    "MODEL_PATH = \"rnn_model.h5\"\n",
    "TOKENIZER_PATH = \"tokenizer.pkl\"\n",
    "LABEL_ENCODER_PATH = \"label_encoder.pkl\"\n",
    "MAX_SEQUENCE_LENGTH = 100\n",
    "EMBEDDING_DIM = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Login using e.g. `huggingface-cli login` to access this dataset\n",
    "splits = {'train': 'train.csv', 'validation': 'dev.csv', 'test': 'test.csv'}\n",
    "df = pd.read_csv(\"hf://datasets/ibm-research/argument_quality_ranking_30k/\" + splits[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>argument</th>\n",
       "      <th>topic</th>\n",
       "      <th>set</th>\n",
       "      <th>WA</th>\n",
       "      <th>MACE-P</th>\n",
       "      <th>stance_WA</th>\n",
       "      <th>stance_WA_conf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"marriage\" isn't keeping up with the times.  a...</td>\n",
       "      <td>We should abandon marriage</td>\n",
       "      <td>train</td>\n",
       "      <td>0.846165</td>\n",
       "      <td>0.297659</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>.a multi-party system would be too confusing a...</td>\n",
       "      <td>We should adopt a multi-party system</td>\n",
       "      <td>train</td>\n",
       "      <td>0.891271</td>\n",
       "      <td>0.726133</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>`people reach their limit when it comes to the...</td>\n",
       "      <td>Assisted suicide should be a criminal offence</td>\n",
       "      <td>train</td>\n",
       "      <td>0.730395</td>\n",
       "      <td>0.225212</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100% agree, should they do that, it would be a...</td>\n",
       "      <td>We should abolish safe spaces</td>\n",
       "      <td>train</td>\n",
       "      <td>0.236686</td>\n",
       "      <td>0.004104</td>\n",
       "      <td>1</td>\n",
       "      <td>0.805517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A ban on naturopathy creates a cohesive front ...</td>\n",
       "      <td>We should ban naturopathy</td>\n",
       "      <td>train</td>\n",
       "      <td>0.753805</td>\n",
       "      <td>0.337724</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            argument  \\\n",
       "0  \"marriage\" isn't keeping up with the times.  a...   \n",
       "1  .a multi-party system would be too confusing a...   \n",
       "2  `people reach their limit when it comes to the...   \n",
       "3  100% agree, should they do that, it would be a...   \n",
       "4  A ban on naturopathy creates a cohesive front ...   \n",
       "\n",
       "                                           topic    set        WA    MACE-P  \\\n",
       "0                     We should abandon marriage  train  0.846165  0.297659   \n",
       "1           We should adopt a multi-party system  train  0.891271  0.726133   \n",
       "2  Assisted suicide should be a criminal offence  train  0.730395  0.225212   \n",
       "3                  We should abolish safe spaces  train  0.236686  0.004104   \n",
       "4                      We should ban naturopathy  train  0.753805  0.337724   \n",
       "\n",
       "   stance_WA  stance_WA_conf  \n",
       "0          1        1.000000  \n",
       "1         -1        1.000000  \n",
       "2         -1        1.000000  \n",
       "3          1        0.805517  \n",
       "4          1        1.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "argument = list(df.argument)\n",
    "topic = list(df.topic)\n",
    "note = list(df.WA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for i in range(len(argument)):\n",
    "    data.append((argument[i] + topic[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Bidirectional, LSTM\n",
    "\n",
    "# Charger le tokenizer et le modèle BERT\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "bert_model = AutoModel.from_pretrained(\"bert-base-multilingual-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20974"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "print(list([1,2,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [02:16<00:00, 15.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(249, 100, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Exemple de données\n",
    "texts = data[:2000]\n",
    "\n",
    "batch_size = 249  # Ajustez cette valeur en fonction de votre RAM\n",
    "\n",
    "all_bert_embeddings = []\n",
    "\n",
    "for i in tqdm(range(0, len(texts), batch_size)):\n",
    "    batch_texts = texts[i : i + batch_size]\n",
    "    encoded_inputs = tokenizer(\n",
    "        batch_texts,\n",
    "        padding=\"max_length\",  # Forcer le padding à une longueur fixe\n",
    "        truncation=True,\n",
    "        max_length=MAX_SEQUENCE_LENGTH,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(**encoded_inputs)\n",
    "        batch_embeddings = outputs.last_hidden_state  # Shape: (batch_size, max_length, hidden_size)\n",
    "    \n",
    "    all_bert_embeddings.append(batch_embeddings.numpy())\n",
    "\n",
    "print(all_bert_embeddings[0].shape)\n",
    "# Concaténer tous les embeddings en un seul tableau numpy\n",
    "bert_embeddings = np.concatenate(all_bert_embeddings, axis=0)\n",
    "\n",
    "# Entraîner le modèle avec des données d'entraînement adaptées\n",
    "# model.fit(bert_embeddings_train, y_train, validation_data=(bert_embeddings_test, y_test), epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(bert_embeddings, np.array(list(note)[:2000]), test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construire le modèle LSTM avec les embeddings de BERT\n",
    "model = Sequential()\n",
    "\n",
    "# Ajouter des couches bidirectionnelles LSTM\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=True, input_shape=(MAX_SEQUENCE_LENGTH, bert_embeddings.shape[-1]))))\n",
    "model.add(Bidirectional(LSTM(64)))\n",
    "\n",
    "# Ajouter des couches denses\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "# Compiler le modèle\n",
    "model.compile(loss='mean_absolute_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "50/50 [==============================] - 11s 166ms/step - loss: 0.1685 - val_loss: 0.1671\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 7s 144ms/step - loss: 0.1329 - val_loss: 0.1347\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 7s 142ms/step - loss: 0.1211 - val_loss: 0.1286\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 7s 144ms/step - loss: 0.1145 - val_loss: 0.1242\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 7s 144ms/step - loss: 0.1038 - val_loss: 0.1286\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 7s 147ms/step - loss: 0.0985 - val_loss: 0.1535\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 8s 153ms/step - loss: 0.1017 - val_loss: 0.1285\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 8s 153ms/step - loss: 0.0922 - val_loss: 0.1367\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 8s 153ms/step - loss: 0.0859 - val_loss: 0.1300\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 8s 163ms/step - loss: 0.0772 - val_loss: 0.1298\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7d1c86050700>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and evaluate model with train and test\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data):\n",
    "    data = [data]\n",
    "    # Tokenisation et encodage des textes\n",
    "    encoded_inputs = tokenizer(data, padding=True, truncation=True, max_length=MAX_SEQUENCE_LENGTH, return_tensors=\"pt\")\n",
    "    # Obtenir les embeddings de BERT\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(**encoded_inputs)\n",
    "        # Utiliser les embeddings de la dernière couche cachée\n",
    "        bert_embeddings = outputs.last_hidden_state  # Shape: (batch_size, sequence_length, hidden_size)\n",
    "\n",
    "    # Convertir les embeddings en numpy pour Keras\n",
    "    bert_embeddings = bert_embeddings.numpy()\n",
    "    print(bert_embeddings.shape)\n",
    "    prediction = model.predict(bert_embeddings)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 22, 768)\n",
      "1/1 [==============================] - 1s 689ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.7031841]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arg = \"a zero tolerance policy means that parents would give complete control of discipline to the school without any regard for family morals and teachings.\"\n",
    "top = \"We should adopt a zero-tolerance policy in schools\"\n",
    "predict(arg + top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
