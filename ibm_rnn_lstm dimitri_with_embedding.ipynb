{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dimitri/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Suppress INFO and WARNING messages\n",
    "import argparse\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import joblib\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "## train test split\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "n_missing = 3\n",
    "MODEL_PATH = \"rnn_model.h5\"\n",
    "TOKENIZER_PATH = \"tokenizer.pkl\"\n",
    "LABEL_ENCODER_PATH = \"label_encoder.pkl\"\n",
    "MAX_SEQUENCE_LENGTH = 100\n",
    "EMBEDDING_DIM = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Login using e.g. `huggingface-cli login` to access this dataset\n",
    "splits = {'train': 'train.csv', 'validation': 'dev.csv', 'test': 'test.csv'}\n",
    "df = pd.read_csv(\"hf://datasets/ibm-research/argument_quality_ranking_30k/\" + splits[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>argument</th>\n",
       "      <th>topic</th>\n",
       "      <th>set</th>\n",
       "      <th>WA</th>\n",
       "      <th>MACE-P</th>\n",
       "      <th>stance_WA</th>\n",
       "      <th>stance_WA_conf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"marriage\" isn't keeping up with the times.  a...</td>\n",
       "      <td>We should abandon marriage</td>\n",
       "      <td>train</td>\n",
       "      <td>0.846165</td>\n",
       "      <td>0.297659</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>.a multi-party system would be too confusing a...</td>\n",
       "      <td>We should adopt a multi-party system</td>\n",
       "      <td>train</td>\n",
       "      <td>0.891271</td>\n",
       "      <td>0.726133</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>`people reach their limit when it comes to the...</td>\n",
       "      <td>Assisted suicide should be a criminal offence</td>\n",
       "      <td>train</td>\n",
       "      <td>0.730395</td>\n",
       "      <td>0.225212</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100% agree, should they do that, it would be a...</td>\n",
       "      <td>We should abolish safe spaces</td>\n",
       "      <td>train</td>\n",
       "      <td>0.236686</td>\n",
       "      <td>0.004104</td>\n",
       "      <td>1</td>\n",
       "      <td>0.805517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A ban on naturopathy creates a cohesive front ...</td>\n",
       "      <td>We should ban naturopathy</td>\n",
       "      <td>train</td>\n",
       "      <td>0.753805</td>\n",
       "      <td>0.337724</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            argument  \\\n",
       "0  \"marriage\" isn't keeping up with the times.  a...   \n",
       "1  .a multi-party system would be too confusing a...   \n",
       "2  `people reach their limit when it comes to the...   \n",
       "3  100% agree, should they do that, it would be a...   \n",
       "4  A ban on naturopathy creates a cohesive front ...   \n",
       "\n",
       "                                           topic    set        WA    MACE-P  \\\n",
       "0                     We should abandon marriage  train  0.846165  0.297659   \n",
       "1           We should adopt a multi-party system  train  0.891271  0.726133   \n",
       "2  Assisted suicide should be a criminal offence  train  0.730395  0.225212   \n",
       "3                  We should abolish safe spaces  train  0.236686  0.004104   \n",
       "4                      We should ban naturopathy  train  0.753805  0.337724   \n",
       "\n",
       "   stance_WA  stance_WA_conf  \n",
       "0          1        1.000000  \n",
       "1         -1        1.000000  \n",
       "2         -1        1.000000  \n",
       "3          1        0.805517  \n",
       "4          1        1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "argument = list(df.argument)\n",
    "topic = list(df.topic)\n",
    "note = list(df.WA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/dimitri/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemple de vocabulaire : ['<PAD>', 'should', 'we', 'the', 'to', '.', 'and', 'of', 'a', 'be']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "PADDINGS_TOPICS = 10\n",
    "PADDINGS_ARGUMENTS = 100\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "data = []\n",
    "for i in range(len(argument)):\n",
    "    arg_token = word_tokenize(argument[i].lower())\n",
    "    arg_topic = word_tokenize(topic[i].lower())\n",
    "    if len(arg_topic) < PADDINGS_TOPICS:\n",
    "        arg_topic += ['<PAD>'] * (PADDINGS_TOPICS - len(arg_topic))\n",
    "    if len(arg_token) < PADDINGS_ARGUMENTS:\n",
    "        arg_token += ['<PAD>'] * (PADDINGS_ARGUMENTS - len(arg_token))\n",
    "\n",
    "    data.append(arg_topic + arg_token)\n",
    "\n",
    "model_embedding = Word2Vec(sentences=data, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "print(\"Exemple de vocabulaire :\", list(model_embedding.wv.key_to_index.keys())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sentence_to_vec(sentence, model):\n",
    "    vectors = []\n",
    "    for word in sentence:\n",
    "        if word in model.wv:\n",
    "            vectors.append(model.wv[word])\n",
    "        else:\n",
    "            vectors.append(np.zeros(model.vector_size))  # Use zero vector for unknown words\n",
    "    return np.array(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([sentence_to_vec(sent, model_embedding) for sent in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, np.array(list(note)), test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Bidirectional, LSTM\n",
    "# Construire le modèle LSTM avec les embeddings de BERT\n",
    "model = Sequential()\n",
    "\n",
    "# Ajouter des couches bidirectionnelles LSTM\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=True, input_shape=(MAX_SEQUENCE_LENGTH, X.shape[-1]))))\n",
    "model.add(Bidirectional(LSTM(64)))\n",
    "\n",
    "# Ajouter des couches denses\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compiler le modèle\n",
    "model.compile(loss='mean_absolute_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "525/525 [==============================] - 71s 128ms/step - loss: 0.1448 - val_loss: 0.1409\n",
      "Epoch 2/2\n",
      "525/525 [==============================] - 76s 146ms/step - loss: 0.1382 - val_loss: 0.1378\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7249a5b7ac50>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and evaluate model with train and test\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=2, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(topic, arg):\n",
    "    arg_token = word_tokenize(arg.lower())\n",
    "    arg_topic = word_tokenize(topic.lower())\n",
    "    arg_topic += ['<PAD>'] * (PADDINGS_TOPICS - len(arg_topic))\n",
    "    arg_token += ['<PAD>'] * (PADDINGS_ARGUMENTS - len(arg_token))\n",
    "    return arg_topic + arg_token\n",
    "\n",
    "def predict(arguments, topics):\n",
    "    data = []\n",
    "    for i in range(len(arguments)):\n",
    "        data.append(prepare_data(topics[i], arguments[i]))\n",
    "    X = []\n",
    "    for i in range(len(data)):\n",
    "        tmp = sentence_to_vec(data[i], model_embedding)\n",
    "        X.append(tmp)\n",
    "    X = np.array(X)\n",
    "    y_pred = model.predict(X, verbose=0)\n",
    "    return y_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load le test\n",
    "df_test = pd.read_csv(\"hf://datasets/ibm-research/argument_quality_ranking_30k/\" + splits[\"test\"])\n",
    "argument_test = list(df_test.argument)\n",
    "topic_test = list(df_test.topic)\n",
    "note_test = np.array(list(df_test.WA)).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0: MAE = 0.1348197033131609\n",
      "Batch 1: MAE = 0.12478841887783385\n",
      "Batch 2: MAE = 0.1258744259654185\n",
      "Batch 3: MAE = 0.12368547179374362\n",
      "Batch 4: MAE = 0.12532738973574295\n",
      "Batch 5: MAE = 0.12332791638120875\n",
      "Batch 6: MAE = 0.12527829892735307\n",
      "Batch 7: MAE = 0.1277237428530481\n",
      "MAE = 0.1277237428530481\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "batch_size = 32\n",
    "acc = 0\n",
    "stop = 200\n",
    "for i in range(0, len(topic_test), batch_size):\n",
    "    batch_topic = topic_test[i:i + batch_size]\n",
    "    batch_argument = argument_test[i:i + batch_size]\n",
    "    y_preds = predict(batch_argument, batch_topic)\n",
    "    predictions.extend(y_preds)\n",
    "    acc += np.sum(np.abs(y_preds - note_test[i:i + batch_size])) / len(y_preds)\n",
    "    print(\"Batch {}: MAE = {}\".format(i // batch_size, acc / (i // batch_size + 1)))\n",
    "    if i >= stop:\n",
    "        break\n",
    "print(\"MAE = {}\".format(acc / (i // batch_size + 1)))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['we', 'should', 'adopt', 'a', 'zero-tolerance', 'policy', 'in', 'schools', '<PAD>', '<PAD>', 'a', 'zero', 'tolerance', 'policy', 'means', 'that', 'parents', 'would', 'give', 'complete', 'control', 'of', 'discipline', 'to', 'the', 'school', 'without', 'any', 'regard', 'for', 'family', 'morals', 'and', 'teachings', '.', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']]\n",
      "zero-tolerance\n",
      "(1, 110, 100)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.88045317]], dtype=float32)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arg = \"a zero tolerance policy means that parents would give complete control of discipline to the school without any regard for family morals and teachings.\"\n",
    "top = \"We should adopt a zero-tolerance policy in schools\"\n",
    "predict([arg], [top])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Exemple de prédictions\n",
    "preds = np.random.rand(1000)\n",
    "classes = np.floor(preds * 10).astype(int)\n",
    "\n",
    "plt.hist(classes, bins=np.arange(12)-0.5, edgecolor='black', rwidth=0.8)\n",
    "plt.xticks(range(11))\n",
    "plt.xlabel(\"Classe de prédiction (intervalle de 0.1)\")\n",
    "plt.ylabel(\"Nombre de prédictions\")\n",
    "plt.title(\"Distribution des classes de prédictions (LSTM)\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
