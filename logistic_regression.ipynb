{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Logistic Regression",
   "id": "9c3049aa40c96d4f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T14:46:52.499346Z",
     "start_time": "2025-03-31T14:46:49.439981Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ],
   "id": "8fa8f345d972e160",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'torch' has no attribute '_subclasses' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfeature_extraction\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtext\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m TfidfVectorizer\n\u001B[0;32m----> 4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01msentence_transformers\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m SentenceTransformer\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfeature_extraction\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtext\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m CountVectorizer\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodel_selection\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m train_test_split\n",
      "File \u001B[0;32m~/Desktop/Epita/Algo/NLP_project/lib/python3.9/site-packages/sentence_transformers/__init__.py:9\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mimportlib\u001B[39;00m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mos\u001B[39;00m\n\u001B[0;32m----> 9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01msentence_transformers\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackend\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m     10\u001B[0m     export_dynamic_quantized_onnx_model,\n\u001B[1;32m     11\u001B[0m     export_optimized_onnx_model,\n\u001B[1;32m     12\u001B[0m     export_static_quantized_openvino_model,\n\u001B[1;32m     13\u001B[0m )\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01msentence_transformers\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcross_encoder\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mCrossEncoder\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m CrossEncoder\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01msentence_transformers\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdatasets\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ParallelSentencesDataset, SentencesDataset\n",
      "File \u001B[0;32m~/Desktop/Epita/Algo/NLP_project/lib/python3.9/site-packages/sentence_transformers/backend.py:11\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtyping\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m TYPE_CHECKING, Callable, Literal\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mhuggingface_hub\u001B[39;00m\n\u001B[0;32m---> 11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01msentence_transformers\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutil\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m disable_datasets_caching, is_datasets_available\n\u001B[1;32m     13\u001B[0m logger \u001B[38;5;241m=\u001B[39m logging\u001B[38;5;241m.\u001B[39mgetLogger(\u001B[38;5;18m__name__\u001B[39m)\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m TYPE_CHECKING:\n",
      "File \u001B[0;32m~/Desktop/Epita/Algo/NLP_project/lib/python3.9/site-packages/sentence_transformers/util.py:17\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mnumpy\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mrequests\u001B[39;00m\n\u001B[0;32m---> 17\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mhuggingface_hub\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m hf_hub_download, snapshot_download\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Tensor, device\n",
      "File \u001B[0;32m~/Desktop/Epita/Algo/NLP_project/lib/python3.9/site-packages/torch/__init__.py:2604\u001B[0m\n\u001B[1;32m   2600\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfunc\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m vmap \u001B[38;5;28;01mas\u001B[39;00m vmap\n\u001B[1;32m   2603\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m TYPE_CHECKING:\n\u001B[0;32m-> 2604\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m _meta_registrations\n\u001B[1;32m   2606\u001B[0m \u001B[38;5;66;03m# Enable CUDA Sanitizer\u001B[39;00m\n\u001B[1;32m   2607\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTORCH_CUDA_SANITIZER\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m os\u001B[38;5;241m.\u001B[39menviron:\n",
      "File \u001B[0;32m~/Desktop/Epita/Algo/NLP_project/lib/python3.9/site-packages/torch/_meta_registrations.py:11\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_prims_common\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mutils\u001B[39;00m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m SymBool, SymFloat, Tensor\n\u001B[0;32m---> 11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_decomp\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m     12\u001B[0m     _add_op_to_registry,\n\u001B[1;32m     13\u001B[0m     _convert_out_params,\n\u001B[1;32m     14\u001B[0m     global_decomposition_table,\n\u001B[1;32m     15\u001B[0m     meta_table,\n\u001B[1;32m     16\u001B[0m )\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_ops\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m OpOverload\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_prims\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m _prim_elementwise_meta, ELEMENTWISE_PRIM_TYPE_PROMOTION_KIND\n",
      "File \u001B[0;32m~/Desktop/Epita/Algo/NLP_project/lib/python3.9/site-packages/torch/_decomp/__init__.py:285\u001B[0m\n\u001B[1;32m    283\u001B[0m \u001B[38;5;66;03m# populate the table\u001B[39;00m\n\u001B[1;32m    284\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_decomp\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdecompositions\u001B[39;00m\n\u001B[0;32m--> 285\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_refs\u001B[39;00m\n\u001B[1;32m    288\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mcore_aten_decompositions\u001B[39m() \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCustomDecompTable\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    289\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexport\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexported_program\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m default_decompositions\n",
      "File \u001B[0;32m~/Desktop/Epita/Algo/NLP_project/lib/python3.9/site-packages/torch/_refs/__init__.py:3307\u001B[0m\n\u001B[1;32m   3303\u001B[0m         rstd \u001B[38;5;241m=\u001B[39m _maybe_convert_to_dtype(rstd, \u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39mdtype)  \u001B[38;5;66;03m# type: ignore[assignment]\u001B[39;00m\n\u001B[1;32m   3304\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (out, mean, rstd)\n\u001B[0;32m-> 3307\u001B[0m \u001B[38;5;129m@torch\u001B[39m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_subclasses\u001B[49m\u001B[38;5;241m.\u001B[39mfake_impls\u001B[38;5;241m.\u001B[39mregister_op_impl(aten\u001B[38;5;241m.\u001B[39mnative_layer_norm\u001B[38;5;241m.\u001B[39mdefault)\n\u001B[1;32m   3308\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mnative_layer_norm_fake\u001B[39m(fake_mode, func, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m   3309\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m native_layer_norm(\u001B[38;5;241m*\u001B[39margs)\n\u001B[1;32m   3312\u001B[0m \u001B[38;5;66;03m# TODO: Adding this as a meta function causes functorch tests to fail when compiled with debug mode.\u001B[39;00m\n\u001B[1;32m   3313\u001B[0m \u001B[38;5;66;03m# test/test_eager_transforms.py::TestFunctionalizeCPU::test_functionalize_fx_transpose_simple_cpu\u001B[39;00m\n",
      "\u001B[0;31mAttributeError\u001B[0m: partially initialized module 'torch' has no attribute '_subclasses' (most likely due to a circular import)"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Data Preprocessing\n",
    "Choose what you want to evaluate:\n",
    "- `KIND`: predict if the prompt is human or AI generated\n",
    "- `GRADE`: predict the quality of the model"
   ],
   "id": "17dcc2d268b712f1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T14:46:36.344212Z",
     "start_time": "2025-03-31T14:45:28.697938Z"
    }
   },
   "cell_type": "code",
   "source": [
    "LABEL_TYPE = 'KIND'  # Choose from 'KIND', 'GRADE'\n",
    "\n",
    "df = pd.read_parquet(\"hf://datasets/data-is-better-together/10k_prompts_ranked/data/train-00000-of-00001.parquet\")\n",
    "\n",
    "#df = df[df[\"num_responses\"] > 1]\n",
    "df = df[df[\"agreement_ratio\"] > 0.4]\n",
    "\n",
    "if LABEL_TYPE == 'KIND':\n",
    "    df[\"label_binary\"] = df[\"kind\"].apply(lambda x: 1 if x == \"human\" else 0)\n",
    "elif LABEL_TYPE == 'GRADE':\n",
    "    df[\"label_binary\"] = df[\"avg_rating\"].apply(lambda x: 1 if x >= 4 else 0)\n",
    "else:\n",
    "    raise ValueError(\"Invalid LABEL_TYPE. Choose from 'KIND', 'GRADE'\")\n",
    "\n",
    "X = df[\"prompt\"]\n",
    "y = df[\"label_binary\"]\n"
   ],
   "id": "6d1e038fb1b525d8",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m LABEL_TYPE \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mKIND\u001B[39m\u001B[38;5;124m'\u001B[39m  \u001B[38;5;66;03m# Choose from 'KIND', 'GRADE'\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241m.\u001B[39mread_parquet(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdataset.parquet\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m#df = df[df[\"num_responses\"] > 1]\u001B[39;00m\n\u001B[1;32m      6\u001B[0m df \u001B[38;5;241m=\u001B[39m df[df[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124magreement_ratio\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0.4\u001B[39m]\n",
      "\u001B[0;31mNameError\u001B[0m: name 'pd' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Tokenize Prompts\n",
    "- Bag of words\n",
    "- TF-IDF\n",
    "- Transformer-Based Sentence Embedding\n",
    "\n",
    "Choose the type of tokenizer you want"
   ],
   "id": "4fd80c9ca27db7e9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "TOKENIZER_TYPE = 'BOW'  # Choose from 'BOW', 'TF-IDF', 'TRANSFORMER'\n",
    "\n",
    "# BAG OF WORDS\n",
    "if TOKENIZER_TYPE == 'BOW':\n",
    "    tokenizer = CountVectorizer()\n",
    "    X = tokenizer.fit_transform(X)\n",
    "\n",
    "# TF-IDF\n",
    "elif TOKENIZER_TYPE == 'TF-IDF':\n",
    "    tokenizer = TfidfVectorizer()\n",
    "    X = tokenizer.fit_transform(X)\n",
    "\n",
    "# TRANSFORMER-BASED SENTENCE EMBEDDING\n",
    "elif TOKENIZER_TYPE == 'TRANSFORMER':\n",
    "    tokenizer = SentenceTransformer(\"distilbert-base-nli-stsb-mean-tokens\")  # Lightweight and fast\n",
    "    X = tokenizer.encode(X.tolist())\n",
    "\n",
    "else:\n",
    "    raise ValueError(\"Invalid TOKENIZER_TYPE. Choose from 'BOW', 'TF-IDF', 'TRANSFORMER'\")"
   ],
   "id": "5110375ecb55d7db"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Train Model",
   "id": "2b8f7eabe5150d7e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=123\n",
    ")\n",
    "\n",
    "# Define the model hyperparameters\n",
    "params = {\n",
    "    \"solver\": \"lbfgs\",\n",
    "    \"max_iter\": 100,\n",
    "    \"multi_class\": \"auto\",\n",
    "    \"random_state\": 8888,\n",
    "}\n",
    "\n",
    "# Train the model\n",
    "lr = LogisticRegression(**params)\n",
    "lr.fit(X_train, y_train)"
   ],
   "id": "efbd60bc740a7ecb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Evaluate Model",
   "id": "8100a2bd8991ed7d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Predict on the test set\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average=\"weighted\")\n",
    "recall = recall_score(y_test, y_pred, average=\"weighted\")\n",
    "f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ],
   "id": "2edb08f444a3929d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Make prediction\n",
    "\n",
    "- Change the prompt as you want to evaluate it"
   ],
   "id": "516c1ac1f62c682"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "PROMPT = \"\"\"I love bananas, can you make a recipe out of it ?\"\"\"\n",
    "\n",
    "if TOKENIZER_TYPE == 'BOW' or TOKENIZER_TYPE == 'TF-IDF':\n",
    "    prompt_vector = tokenizer.transform([PROMPT])\n",
    "elif TOKENIZER_TYPE == 'TRANSFORMER':\n",
    "    prompt_vector = tokenizer.encode([PROMPT])\n",
    "else:\n",
    "    raise ValueError(\"Invalid TOKENIZER_TYPE. Choose from 'BOW', 'TF-IDF', 'TRANSFORMER'\")\n",
    "\n",
    "print(f\"\\nPrompt: {PROMPT}\")\n",
    "prediction = lr.predict(prompt_vector)\n",
    "print(f\"Prediction: {prediction[0]}\")"
   ],
   "id": "b84d46d1e50874ad"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
