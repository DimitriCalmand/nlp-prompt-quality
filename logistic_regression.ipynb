{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c3049aa40c96d4f",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fa8f345d972e160",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T14:46:52.499346Z",
     "start_time": "2025-03-31T14:46:49.439981Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dimitri/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-05-07 10:13:42.615541: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-05-07 10:13:43.850312: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d1e038fb1b525d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T14:46:36.344212Z",
     "start_time": "2025-03-31T14:45:28.697938Z"
    }
   },
   "outputs": [],
   "source": [
    "# Login using e.g. `huggingface-cli login` to access this dataset\n",
    "splits = {'train': 'train.csv', 'validation': 'dev.csv', 'test': 'test.csv'}\n",
    "df = pd.read_csv(\"hf://datasets/ibm-research/argument_quality_ranking_30k/\" + splits[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a1b46144",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df[df[\"num_responses\"] > 1]\n",
    "PADDING_TOPIC = 15\n",
    "PADDING_ARG = 100\n",
    "\n",
    "REGRESSION = True\n",
    "if REGRESSION:\n",
    "    df[\"label_binary\"] = df[\"MACE-P\"]\n",
    "else:\n",
    "    df[\"label_binary\"] = df[\"MACE-P\"].apply(lambda x: 1 if x > 0.5 else 0)\n",
    "\n",
    "y = df[\"label_binary\"]\n",
    "X = []\n",
    "for i in range(len(df)):\n",
    "    topic = df[\"topic\"][i] + \" <PAD>\" * (PADDING_TOPIC - len(df[\"topic\"][i].split()))\n",
    "    arg = df[\"argument\"][i] + \" <PAD>\" * (PADDING_ARG - len(df[\"argument\"][i].split()))\n",
    "    X.append(topic + \" \" + arg)\n",
    "X = pd.Series(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd80c9ca27db7e9",
   "metadata": {},
   "source": [
    "## Tokenize Prompts\n",
    "- Bag of words\n",
    "- TF-IDF\n",
    "- Transformer-Based Sentence Embedding\n",
    "\n",
    "Choose the type of tokenizer you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5110375ecb55d7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENIZER_TYPE = 'BOW'  # Choose from 'BOW', 'TF-IDF', 'TRANSFORMER'\n",
    "\n",
    "# BAG OF WORDS\n",
    "if TOKENIZER_TYPE == 'BOW':\n",
    "    tokenizer = CountVectorizer()\n",
    "    X = tokenizer.fit_transform(X)\n",
    "\n",
    "# TF-IDF\n",
    "elif TOKENIZER_TYPE == 'TF-IDF':\n",
    "    tokenizer = TfidfVectorizer()\n",
    "    X = tokenizer.fit_transform(X)\n",
    "\n",
    "# TRANSFORMER-BASED SENTENCE EMBEDDING\n",
    "elif TOKENIZER_TYPE == 'TRANSFORMER':\n",
    "    tokenizer = SentenceTransformer(\"distilbert-base-nli-stsb-mean-tokens\")  # Lightweight and fast\n",
    "    X = tokenizer.encode(X.tolist())\n",
    "\n",
    "else:\n",
    "    raise ValueError(\"Invalid TOKENIZER_TYPE. Choose from 'BOW', 'TF-IDF', 'TRANSFORMER'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8f7eabe5150d7e",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "efbd60bc740a7ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=123\n",
    ")\n",
    "\n",
    "if REGRESSION:\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "\n",
    "    # Train a regression model\n",
    "    reg = LinearRegression()\n",
    "    reg.fit(X_train, y_train)\n",
    "else:\n",
    "    # Define the model hyperparameters\n",
    "    params = {\n",
    "        \"solver\": \"lbfgs\",\n",
    "        \"max_iter\": 500,\n",
    "        \"multi_class\": \"auto\",\n",
    "        \"random_state\": 8888,\n",
    "    }\n",
    "\n",
    "    # Train the model\n",
    "    lr = LogisticRegression(**params)\n",
    "    lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8100a2bd8991ed7d",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edb08f444a3929d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.24086942722015747\n",
      "Mean Absolute Error (MAE): 0.3825032522391897\n",
      "R-squared (R2): -0.7788747705609178\n"
     ]
    }
   ],
   "source": [
    "if REGRESSION:\n",
    "    from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = reg.predict(X_test)\n",
    "\n",
    "    # Calculate regression metrics\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "    print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "else:\n",
    "    # Predict on the test set\n",
    "    y_pred = lr.predict(X_test)\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average=\"weighted\")\n",
    "    recall = recall_score(y_test, y_pred, average=\"weighted\")\n",
    "    f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516c1ac1f62c682",
   "metadata": {},
   "source": [
    "## Make prediction\n",
    "\n",
    "- Change the prompt as you want to evaluate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b84d46d1e50874ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt: Assisted suicide should be a criminal offence <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> `people reach their limit when it comes to their quality of life and should be able to end their suffering. this can be done with little or no suffering by assistance and the person is able to say good bye. <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Prediction: 1\n"
     ]
    }
   ],
   "source": [
    "def prepare_data(topic, arg):\n",
    "    topic = topic + \" <PAD>\" * (PADDING_TOPIC - len(topic.split()))\n",
    "    arg = arg + \" <PAD>\" * (PADDING_ARG - len(arg.split()))\n",
    "    return topic + \" \" + arg\n",
    "PROMPT = prepare_data(\"Assisted suicide should be a criminal offence\",\"`people reach their limit when it comes to their quality of life and should be able to end their suffering. this can be done with little or no suffering by assistance and the person is able to say good bye.\")\n",
    "if TOKENIZER_TYPE == 'BOW' or TOKENIZER_TYPE == 'TF-IDF':\n",
    "    prompt_vector = tokenizer.transform([PROMPT])\n",
    "elif TOKENIZER_TYPE == 'TRANSFORMER':\n",
    "    prompt_vector = tokenizer.encode([PROMPT])\n",
    "else:\n",
    "    raise ValueError(\"Invalid TOKENIZER_TYPE. Choose from 'BOW', 'TF-IDF', 'TRANSFORMER'\")\n",
    "\n",
    "print(f\"\\nPrompt: {PROMPT}\")\n",
    "prediction = lr.predict(prompt_vector)\n",
    "print(f\"Prediction: {prediction[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d471ebf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
