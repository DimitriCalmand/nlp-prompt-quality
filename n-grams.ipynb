{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab8c302d-65eb-4a99-b7b4-fac1333986bd",
   "metadata": {},
   "source": [
    "# Course 2 - N-grams\n",
    "\n",
    "## Import librairies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a9b0544-e1af-43c0-beaf-a19b047f9895",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "import math\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902dd652-441b-439e-90fd-3c9c3ad0ef93",
   "metadata": {},
   "source": [
    "## Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c9688d96-218a-4bee-b80a-a87ec677dafb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_list shape : (5166,)\n",
      "test_list shape : (5165,)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet(\"hf://datasets/data-is-better-together/10k_prompts_ranked/data/train-00000-of-00001.parquet\")\n",
    "train_test = df.prompt\n",
    "\n",
    "percentage_train_test = int(train_test.shape[0]//2)\n",
    "train_list = train_test[percentage_train_test:]\n",
    "test_list = train_test[:percentage_train_test]\n",
    "print(f\"train_list shape : {train_list.shape}\")\n",
    "print(f\"test_list shape : {test_list.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4474ec65-c86c-404a-9203-d16bfe06f79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens in the training set: 537073\n",
      "Vocabulary size: 33925\n",
      "Number of tokens in the test set: 546946\n"
     ]
    }
   ],
   "source": [
    "train_strings = \" \".join(train_list)\n",
    "train_strings = train_strings.lower()\n",
    "train_tokens = word_tokenize(train_strings)\n",
    "print(\"Number of tokens in the training set:\",len(train_tokens))\n",
    "\n",
    "vocab = set(train_tokens)\n",
    "print(\"Vocabulary size:\",len(vocab))\n",
    "\n",
    "test_strings = \" \".join(test_list)\n",
    "test_strings = test_strings.lower()\n",
    "test_tokens = word_tokenize(test_strings)\n",
    "print(\"Number of tokens in the test set:\",len(test_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f654303f-e7e4-47bc-8c39-1ce6c21704be",
   "metadata": {},
   "source": [
    "## Train n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3f8cac30-fbdb-4aa0-9560-fe4a52df569a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \"\"\"Tokenize the input text.\"\"\"\n",
    "    \n",
    "    return word_tokenize(text)\n",
    "\n",
    "def count_ngrams(tokens, n):\n",
    "    \"\"\"Counts n-grams.\"\"\"\n",
    "    \n",
    "    ngrams = [tuple(tokens[i:i+n]) for i in range(len(tokens)-n+1)]\n",
    "    \n",
    "    return Counter(ngrams)\n",
    "\n",
    "def calculate_ngram_probabilities(train_tokens, n, test_tokens, k=0.00001):\n",
    "    \"\"\"Calculates n-gram probabilities.\"\"\"\n",
    "    \n",
    "    vocab = set(train_tokens)\n",
    "    V = len(vocab)\n",
    "    ngram_counts = count_ngrams(train_tokens, n)\n",
    "    n_minus_one_gram_counts = count_ngrams(train_tokens, n-1)\n",
    "    ngram_probabilities = defaultdict(float)\n",
    "    \n",
    "    for ngram in ngram_counts:\n",
    "        prefix = ngram[:-1]\n",
    "        ngram_counts[ngram] += k\n",
    "        n_minus_one_gram_counts[prefix] += k\n",
    "        ngram_probabilities[ngram] = (ngram_counts[ngram] + k) / (n_minus_one_gram_counts[prefix] + k*V)\n",
    "\n",
    "    for i in range(len(test_tokens)-n+1):\n",
    "        ngram = tuple(test_tokens[i:i+n])\n",
    "        if ngram not in ngram_counts:\n",
    "            ngram_counts[ngram] = k\n",
    "            prefix = ngram[:-1]\n",
    "            if prefix not in n_minus_one_gram_counts:\n",
    "                n_minus_one_gram_counts[prefix] = k\n",
    "            ngram_probabilities[ngram] = (ngram_counts[ngram] + k) / (n_minus_one_gram_counts[prefix] + k*V)\n",
    "    \n",
    "    return ngram_probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3179fa6a-8f25-40fa-8f39-77b0c9126d05",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c8b98ee6-1265-497c-bbb0-4765bd474946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 5-grams: 950410\n"
     ]
    }
   ],
   "source": [
    "n = 5\n",
    "\n",
    "ngram_probabilities = calculate_ngram_probabilities(train_tokens, n, test_tokens)\n",
    "print(f\"Number of {n}-grams:\",len(ngram_probabilities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e4fc6a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def predict_next_word(ngram_probabilities, context, vocab):\n",
    "    \"\"\"\n",
    "    Prédit le mot suivant en fonction du contexte (n-1 mots).\n",
    "    \"\"\"\n",
    "    context = tuple(context)\n",
    "    candidates = {\n",
    "        ngram[-1]: prob\n",
    "        for ngram, prob in ngram_probabilities.items()\n",
    "        if ngram[:-1] == context\n",
    "    }\n",
    "    \n",
    "    if candidates:\n",
    "        # Trie les candidats par probabilité décroissante et retourne le mot avec la plus haute probabilité\n",
    "        predicted_word = max(candidates.items(), key=lambda x: x[1])[0]\n",
    "        return predicted_word\n",
    "    \n",
    "    # Si le vocabulaire est vide, déclenche une erreur.\n",
    "    if not vocab:\n",
    "        raise ValueError(\"Le vocabulaire est vide.\")\n",
    "    \n",
    "    # Retourne un mot aléatoire si aucun contexte correspondant n'est trouvé\n",
    "    return random.choice(list(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5fc14644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mot prédit : b-yern\n"
     ]
    }
   ],
   "source": [
    "context = [\"I\", \"want\", \"to\", \"understand\"]  # suppose que tu veux prédire après ton test\n",
    "predicted = predict_next_word(ngram_probabilities, context, vocab=set(train_tokens))\n",
    "print(\"Mot prédit :\", predicted)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
