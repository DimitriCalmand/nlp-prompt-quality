{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"hf://datasets/data-is-better-together/10k_prompts_ranked/data/train-00000-of-00001.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/dimitri/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemple de vocabulaire : ['the', ',', '.', 'a', 'and', 'to', 'of', '`', ':', 'in']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Assurez-vous de télécharger le tokenizer\n",
    "nltk.download('punkt')\n",
    "\n",
    "# data contenant vos textes (déjà défini dans votre notebook)\n",
    "# data = df.prompt\n",
    "\n",
    "# Tokenisation de chaque texte en minuscule\n",
    "sentences = data.apply(lambda x: word_tokenize(x.lower())).tolist()\n",
    "\n",
    "# Entraînement du modèle Word2Vec\n",
    "model = Word2Vec(sentences=sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Affichage des premiers mots du vocabulaire\n",
    "print(\"Exemple de vocabulaire :\", list(model.wv.key_to_index.keys())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemple de vecteur pour une phrase Test : [-1.3401253  -1.1962755   0.18973327  0.08268631  0.34668487 -1.8516461\n",
      "  1.3945042   5.341771   -0.21145743 -0.74413496  1.161282   -2.1811602\n",
      "  1.5690962   2.8885422  -1.4018289   0.20991755 -0.46790886 -1.1576248\n",
      "  0.65100265 -1.8396069  -0.05669186 -1.805693   -0.9534167  -1.6135236\n",
      "  0.91928434 -1.4612223   0.31492403 -0.48634875 -1.6666135  -1.9583858\n",
      " -0.03278581  2.3734877   0.20678762 -0.43382517 -1.2921546   1.7613897\n",
      "  0.30660376 -3.3939686  -1.868277   -2.3201137  -0.37695435  0.7171563\n",
      " -1.960806    1.9919307  -0.70470536 -0.74748033 -1.2261251   0.33980167\n",
      " -1.5590177   0.7555095   0.03068616  0.4592432   0.50531256  1.5219619\n",
      "  0.6410132  -0.7868834   0.24140228 -2.791082    0.5008737   1.2051287\n",
      "  0.5889333   0.06846517  0.16249357 -1.7446277  -2.5698276   1.5836375\n",
      " -0.40257394  0.45648634  1.2371472  -1.6199287   1.9610754   0.97774565\n",
      "  0.8717317   1.6990212   0.94643825 -0.70559496  0.30740908 -1.3524894\n",
      " -1.4174275   0.8425299  -0.9530663   1.9101948   0.5353654  -0.2740969\n",
      " -0.60154945  1.6392587  -0.25683644  1.2684392  -0.53476006  0.874142\n",
      "  3.0493236   1.0546137   1.10942     2.353178    3.2593114   1.6436815\n",
      " -2.7095044  -2.1332302   2.0687308  -1.2167776 ]\n"
     ]
    }
   ],
   "source": [
    "test_data  = pd.Series([\"What\"])\n",
    "\n",
    "# Tokenisation de chaque phrase en minuscules\n",
    "test_sentences = test_data.apply(lambda x: word_tokenize(x.lower())).tolist()\n",
    "\n",
    "# Fonction pour calculer un vecteur moyen pour une phrase\n",
    "def sentence_vector(sentence, model):\n",
    "    vectors = [model.wv[word] for word in sentence if word in model.wv]\n",
    "    if vectors:\n",
    "        return np.mean(vectors, axis=0)\n",
    "    return None\n",
    "\n",
    "# Calculer le vecteur moyen pour chaque phrase du dataset Test\n",
    "test_vectors = [sentence_vector(sentence, model) for sentence in test_sentences]\n",
    "\n",
    "# Affichage d'un exemple\n",
    "print(\"Exemple de vecteur pour une phrase Test :\", test_vectors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mots les plus similaires au vecteur de la phrase Test : [('what', 1.0), ('why', 0.8286388516426086), ('how', 0.7310715913772583), ('where', 0.7272747755050659), ('fermat', 0.7128575444221497), ('here', 0.7100605964660645), ('rehash', 0.6909675598144531), ('laundry', 0.6874371767044067), ('moisturize', 0.6774312853813171), ('aware', 0.67348712682724)]\n"
     ]
    }
   ],
   "source": [
    "def decode_embedding(embedding, model, topn=10):\n",
    "    return model.wv.similar_by_vector(embedding, topn=topn)\n",
    "\n",
    "# Décoder le vecteur moyen de la première phrase du dataset Test\n",
    "decoded_words = decode_embedding(test_vectors[0], model)\n",
    "\n",
    "# Affichage des mots les plus similaires\n",
    "print(\"Mots les plus similaires au vecteur de la phrase Test :\", decoded_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
